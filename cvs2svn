#!/usr/bin/env python
# (Be in -*- python -*- mode.)
#
# ====================================================================
# Copyright (c) 2000-2006 CollabNet.  All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution.  The terms
# are also available at http://subversion.tigris.org/license-1.html.
# If newer versions of this license are posted there, you may use a
# newer version instead, at your option.
#
# This software consists of voluntary contributions made by many
# individuals.  For exact contribution history, see the revision
# history and logs, available at http://cvs2svn.tigris.org/.
# ====================================================================

VERSION = 'r' + "$LastChangedRevision$"[22:-2]

import sys

# Make sure this Python is recent enough.  Do this as early as possible,
# using only code compatible with Python 1.5.2 before the check.
if sys.hexversion < 0x02020000:
  sys.stderr.write("ERROR: Python 2.2 or higher required.\n")
  sys.exit(1)

import os
import sha
import re
import time
import fileinput
import getopt
try:
  my_getopt = getopt.gnu_getopt
except AttributeError:
  my_getopt = getopt.getopt
import marshal
import errno
import types

try:
  # Try to get access to a bunch of encodings for use with --encoding.
  # See http://cjkpython.i18n.org/ for details.
  import iconv_codec
except ImportError:
  pass

import cvs2svn_rcsparse

from cvs2svn_lib.boolean import *

from cvs2svn_lib import config

from cvs2svn_lib import common
from cvs2svn_lib.common import \
        warning_prefix, \
        error_prefix, \
        FatalException, \
        FatalError

from cvs2svn_lib.log import Log

from cvs2svn_lib.process import \
        run_command, \
        CommandFailedException, \
        check_command_runs

from cvs2svn_lib import database
from cvs2svn_lib.context import Ctx
from cvs2svn_lib.artifact_manager import artifact_manager
from cvs2svn_lib.stats_keeper import StatsKeeper
from cvs2svn_lib import key_generator
from cvs2svn_lib import cvs_revision
from cvs2svn_lib import cvs_repository
from cvs2svn_lib import property_setters
from cvs2svn_lib.svn_revision_range import SVNRevisionRange
from cvs2svn_lib.tags_database import TagsDatabase
from cvs2svn_lib.cvs_revision import CVSRevision
from cvs2svn_lib.cvs_file_database import CVSFileDatabase
from cvs2svn_lib.cvs_revision_database import CVSRevisionDatabase
from cvs2svn_lib.openings_closings import \
        OpeningsClosingsMap, \
        SymbolingsLogger
from cvs2svn_lib.fill_source import FillSource
from cvs2svn_lib.last_symbolic_name_database import LastSymbolicNameDatabase
from cvs2svn_lib.symbol_database import SymbolDatabase
from cvs2svn_lib.project import Project
from cvs2svn_lib import collect_data
from cvs2svn_lib.symbolings_reader import SymbolingsReader
from cvs2svn_lib.cvs_commit import CVSCommit
from cvs2svn_lib.cvs_revision_aggregator import CVSRevisionAggregator
from cvs2svn_lib.svn_commit_item import SVNCommitItem
from cvs2svn_lib.svn_commit import SVNCommit
from cvs2svn_lib.svn_repository_mirror import \
        SVNRepositoryMirror, \
        SVNRepositoryMirrorDelegate
from cvs2svn_lib.dumpfile_delegate import DumpfileDelegate
from cvs2svn_lib.repository_delegate import RepositoryDelegate
from cvs2svn_lib.stdout_delegate import StdoutDelegate
from cvs2svn_lib.persistence_manager import PersistenceManager
from cvs2svn_lib.pass_manager import \
        PassManager, \
        InvalidPassError


DIGEST_END_IDX = 9 + (sha.digestsize * 2)


ctrl_characters_regexp = re.compile('[\\\x00-\\\x1f\\\x7f]')

def verify_filename_legal(filename):
  """Verify that FILENAME does not include any control characters.  If
  it does, raise a FatalError."""

  m = ctrl_characters_regexp.search(filename)
  if m:
    raise FatalError(
        "Character %r in filename %r is not supported by subversion."
        % (m.group(), filename,))


def sort_file(infilename, outfilename):
  """Sort file INFILENAME, storing the results to OUTFILENAME."""

  # GNU sort will sort our dates differently (incorrectly!) if our
  # LC_ALL is anything but 'C', so if LC_ALL is set, temporarily set
  # it to 'C'
  lc_all_tmp = os.environ.get('LC_ALL', None)
  os.environ['LC_ALL'] = 'C'
  try:
    # The -T option to sort has a nice side effect.  The Win32 sort is
    # case insensitive and cannot be used, and since it does not
    # understand the -T option and dies if we try to use it, there is
    # no risk that we use that sort by accident.
    run_command('sort -T %s %s > %s'
                % (Ctx().tmpdir, infilename, outfilename))
  finally:
    if lc_all_tmp is None:
      del os.environ['LC_ALL']
    else:
      os.environ['LC_ALL'] = lc_all_tmp


class Pass:
  """Base class for one step of the conversion."""

  def __init__(self):
    # By default, use the pass object's class name as the pass name:
    self.name = self.__class__.__name__

  def register_artifacts(self):
    """Register artifacts (created and needed) in artifact_manager."""

    raise NotImplementedError

  def _register_temp_file(self, basename):
    """Helper method; for brevity only."""

    artifact_manager.register_temp_file(basename, self)

  def _register_temp_file_needed(self, basename):
    """Helper method; for brevity only."""

    artifact_manager.register_temp_file_needed(basename, self)

  def run(self):
    """Carry out this step of the conversion."""

    raise NotImplementedError


class CollectRevsPass(Pass):
  """This pass was formerly known as pass1."""

  def register_artifacts(self):
    self._register_temp_file(config.TAGS_LIST)
    self._register_temp_file(config.BRANCHES_LIST)
    self._register_temp_file(config.RESYNC_DATAFILE)
    self._register_temp_file(config.DEFAULT_BRANCHES_DB)
    self._register_temp_file(config.METADATA_DB)
    self._register_temp_file(config.CVS_FILES_DB)
    self._register_temp_file(config.CVS_REVS_DB)
    self._register_temp_file(config.ALL_REVS_DATAFILE)

  def run(self):
    Log().quiet("Examining all CVS ',v' files...")
    cd = collect_data.CollectData()

    def visit_file(baton, dirname, files):
      cd = baton
      for fname in files:
        verify_filename_legal(fname)
        if not fname.endswith(',v'):
          continue
        cd.found_valid_file = 1
        pathname = os.path.join(dirname, fname)

        fdc = collect_data.FileDataCollector(cd, pathname)

        if not fdc.cvs_file.in_attic:
          # If this file also exists in the attic, it's a fatal error
          attic_path = os.path.join(dirname, 'Attic', fname)
          if os.path.exists(attic_path):
            err = "%s: A CVS repository cannot contain both %s and %s" \
                  % (error_prefix, pathname, attic_path)
            sys.stderr.write(err + '\n')
            cd.fatal_errors.append(err)

        Log().normal(pathname)
        try:
          cvs2svn_rcsparse.parse(open(pathname, 'rb'), fdc)
        except (cvs2svn_rcsparse.common.RCSParseError, ValueError,
                RuntimeError):
          err = "%s: '%s' is not a valid ,v file" \
                % (error_prefix, pathname)
          sys.stderr.write(err + '\n')
          cd.fatal_errors.append(err)
        except:
          Log().warn("Exception occurred while parsing %s" % pathname)
          raise

    os.path.walk(Ctx().project.project_cvs_repos_path, visit_file, cd)
    Log().verbose('Processed', cd.num_files, 'files')

    cd.write_symbol_db()

    if len(cd.fatal_errors) > 0:
      raise FatalException("Pass 1 complete.\n"
                           + "=" * 75 + "\n"
                           + "Error summary:\n"
                           + "\n".join(cd.fatal_errors) + "\n"
                           + "Exited due to fatal error(s).\n")

    if cd.found_valid_file is None:
      raise FatalException(
          "\n"
          "No RCS files found in your CVS Repository!\n"
          "Are you absolutely certain you are pointing cvs2svn\n"
          "at a CVS repository?\n"
          "\n"
          "Exited due to fatal error(s).\n")

    StatsKeeper().reset_c_rev_info()
    StatsKeeper().archive()
    Log().quiet("Done")


class ResyncRevsPass(Pass):
  """Clean up the revision information.

  This pass was formerly known as pass2."""

  def register_artifacts(self):
    self._register_temp_file(config.TAGS_DB)
    self._register_temp_file(config.CLEAN_REVS_DATAFILE)
    self._register_temp_file(config.TWEAKED_TIMESTAMPS_DB)
    self._register_temp_file(config.CVS_REVS_RESYNC_DB)
    self._register_temp_file_needed(config.TAGS_LIST)
    self._register_temp_file_needed(config.BRANCHES_LIST)
    self._register_temp_file_needed(config.RESYNC_DATAFILE)
    self._register_temp_file_needed(config.CVS_FILES_DB)
    self._register_temp_file_needed(config.CVS_REVS_DB)
    self._register_temp_file_needed(config.ALL_REVS_DATAFILE)

  def _check_blocked_excludes(self, symbol_db, excludes):
    """Check whether any excluded branches are blocked.

    A branch can be blocked because it has another, non-excluded
    symbol that depends on it.  If any blocked excludes are found,
    output error messages describing the situation.  Return True if
    any errors were found."""

    blocked_excludes = symbol_db.find_blocked_excludes(excludes)
    if not blocked_excludes:
      return False

    for branch, blockers in blocked_excludes.items():
      sys.stderr.write(error_prefix + ": The branch '%s' cannot be "
                       "excluded because the following symbols depend "
                       "on it:\n" % (branch))
      for blocker in blockers:
        sys.stderr.write("    '%s'\n" % (blocker))
    sys.stderr.write("\n")
    return True

  def _check_invalid_forced_tags(self, symbol_db, excludes):
    """Check for commits on any branches that were forced to be tags.

    In that case, they can't be converted into tags.  If any invalid
    forced tags are found, output error messages describing the
    problems.  Return True iff any errors are found."""

    invalid_forced_tags = [ ]
    for forced_tag in Ctx().forced_tags:
      if excludes.has_key(forced_tag):
        continue
      if symbol_db.branch_has_commit(forced_tag):
        invalid_forced_tags.append(forced_tag)

    if not invalid_forced_tags:
      # No problems found:
      return False

    sys.stderr.write(error_prefix + ": The following branches cannot be "
                     "forced to be tags because they have commits:\n")
    for tag in invalid_forced_tags:
      sys.stderr.write("    '%s'\n" % (tag))
    sys.stderr.write("\n")

    return True

  def _check_symbol_mismatches(self, symbol_db, excludes):
    """Check for symbols that are defined as both tags and branches.

    Exclude the symbols in EXCLUDES.  If any are found, output error
    messages describing the problems.  Return True iff any problems
    are found."""

    mismatches = symbol_db.find_mismatches(excludes)

    def is_not_forced(mismatch):
      name = mismatch[0]
      return not (name in Ctx().forced_tags or name in Ctx().forced_branches)

    mismatches = filter(is_not_forced, mismatches)
    if not mismatches:
      # No problems found:
      return False

    sys.stderr.write(error_prefix + ": The following symbols are tags "
                     "in some files and branches in others.\nUse "
                     "--force-tag, --force-branch and/or --exclude to "
                     "resolve the symbols.\n")
    for name, tag_count, branch_count, commit_count in mismatches:
      sys.stderr.write("    '%s' is a tag in %d files, a branch in "
                       "%d files and has commits in %d files.\n"
                       % (name, tag_count, branch_count, commit_count))

    return True

  def _read_resync(self):
    """Read RESYNC_DATAFILE and return its contents.

    Return a map that maps a digest to a sequence of lists which
    specify a lower and upper time bound for matching up the commit:

    { digest -> [[old_time_lower, old_time_upper, new_time], ...] }

    Each triplet is a list because we will dynamically expand the
    lower/upper bound as we find commits that fall into a particular
    msg and time range.  We keep a sequence of these for each digest
    because a number of checkins with the same log message (e.g. an
    empty log message) could need to be remapped.  The lists of
    triplets are sorted by old_time_lower.

    Note that we assume that we can hold the entire resync file in
    memory.  Really large repositories with wacky timestamps could
    bust this assumption.  Should that ever happen, then it is
    possible to split the resync file into pieces and make multiple
    passes, using each piece."""

    DELTA = config.COMMIT_THRESHOLD/2

    resync = { }
    for line in fileinput.FileInput(
            artifact_manager.get_temp_file(config.RESYNC_DATAFILE)):
      [t1, digest, t2] = line.strip().split()
      t1 = int(t1, 16)
      digest = line[9:DIGEST_END_IDX]
      t2 = int(t2, 16)
      resync.setdefault(digest, []).append([t1 - DELTA, t1 + DELTA, t2])

    # For each digest, sort the resync items:
    for val in resync.values():
      val.sort()

    return resync

  def _fix_prev_next_timestamps(self, c_rev, tweaked_timestamps_db):
    """Fix up C_REV.prev_rev and C_REV.next_rev based on the contents
    of TWEAKED_TIMESTAMPS_DB."""

    if c_rev.prev_rev is not None:
      new_prev_ts = tweaked_timestamps_db.get(
        c_rev.prev_rev.unique_key(), None)
      if new_prev_ts:
        c_rev.prev_timestamp = new_prev_ts

    if c_rev.next_rev is not None:
      new_next_ts = tweaked_timestamps_db.get(
        c_rev.next_rev.unique_key(), None)
      if new_next_ts:
        c_rev.next_timestamp = new_next_ts

  def _get_non_excluded_symbols(self, symbols, excludes):
    return [ symbol
             for symbol in symbols
             if symbol not in excludes ]

  def _force_tags(self, c_rev):
    """Convert all branches in C_REV that are forced to be tags."""
    for forced_tag in Ctx().forced_tags:
      if forced_tag in c_rev.branches:
        c_rev.branches.remove(forced_tag)
        c_rev.tags.append(forced_tag)

  def _force_branches(self, c_rev):
    """Convert all tags in C_REV that are forced to be branches."""
    for forced_branch in Ctx().forced_branches:
      if forced_branch in c_rev.tags:
        c_rev.tags.remove(forced_branch)
        c_rev.branches.append(forced_branch)

  def run(self):
    cvs_file_db = CVSFileDatabase(
        artifact_manager.get_temp_file(config.CVS_FILES_DB),
        database.DB_OPEN_READ)
    cvs_revs_db = CVSRevisionDatabase(
        cvs_file_db,
        artifact_manager.get_temp_file(config.CVS_REVS_DB),
        database.DB_OPEN_WRITE)
    cvs_revs_resync_db = CVSRevisionDatabase(
        cvs_file_db,
        artifact_manager.get_temp_file(config.CVS_REVS_RESYNC_DB),
        database.DB_OPEN_NEW)
    symbol_db = SymbolDatabase()
    symbol_db.read()

    # Convert the list of regexps to a list of strings
    excludes = symbol_db.find_excluded_symbols(Ctx().excludes)

    error_detected = False

    Log().quiet("Checking for blocked exclusions...")
    if self._check_blocked_excludes(symbol_db, excludes):
      error_detected = True

    Log().quiet("Checking for forced tags with commits...")
    if self._check_invalid_forced_tags(symbol_db, excludes):
      error_detected = True

    Log().quiet("Checking for tag/branch mismatches...")
    if self._check_symbol_mismatches(symbol_db, excludes):
      error_detected = True

    # Bail out now if we found errors
    if error_detected:
      sys.exit(1)

    # Create the tags database
    tags_db = TagsDatabase(database.DB_OPEN_NEW)
    for tag in symbol_db.tags:
      if tag not in Ctx().forced_branches:
        tags_db.add(tag)
    for tag in Ctx().forced_tags:
      tags_db.add(tag)

    Log().quiet("Re-synchronizing CVS revision timestamps...")

    # We may have recorded some changes in revisions' timestamp.  We need to
    # scan for any other files which may have had the same log message and
    # occurred at "the same time" and change their timestamps, too.

    resync = self._read_resync()

    output = open(artifact_manager.get_temp_file(config.CLEAN_REVS_DATAFILE),
                  'w')

    tweaked_timestamps_db = database.Database(
        artifact_manager.get_temp_file(config.TWEAKED_TIMESTAMPS_DB),
        database.DB_OPEN_NEW)

    # process the revisions file, looking for items to clean up
    for line in open(
            artifact_manager.get_temp_file(config.ALL_REVS_DATAFILE)):
      c_rev_key = line.strip()
      c_rev = cvs_revs_db.get_revision(c_rev_key)

      # Skip this entire revision if it's on an excluded branch
      if c_rev.branch_name in excludes:
        continue

      self._fix_prev_next_timestamps(c_rev, tweaked_timestamps_db)

      c_rev.branches = self._get_non_excluded_symbols(c_rev.branches, excludes)
      c_rev.tags = self._get_non_excluded_symbols(c_rev.tags, excludes)

      self._force_tags(c_rev)
      self._force_branches(c_rev)

      # see if this is "near" any of the resync records we
      # have recorded for this digest [of the log message].
      for record in resync.get(c_rev.digest, []):
        if record[2] == c_rev.timestamp:
          # This means that either c_rev is the same revision that
          # caused the resync record to exist, or c_rev is a different
          # CVS revision that happens to have the same timestamp.  In
          # either case, we don't have to do anything, so we...
          continue

        if record[0] <= c_rev.timestamp <= record[1]:
          # bingo!  We probably want to remap the time on this c_rev,
          # unless the remapping would be useless because the new time
          # would fall outside the COMMIT_THRESHOLD window for this
          # commit group.
          new_timestamp = record[2]
          # If the new timestamp is earlier than that of our previous revision
          if new_timestamp < c_rev.prev_timestamp:
            Log().warn(
                "%s: Attempt to set timestamp of revision %s on file %s"
                " to time %s, which is before previous the time of"
                " revision %s (%s):"
                % (warning_prefix, c_rev.rev, c_rev.cvs_path, new_timestamp,
                   c_rev.prev_rev.rev, c_rev.prev_timestamp))

            # If resyncing our rev to c_rev.prev_timestamp + 1 will place
            # the timestamp of c_rev within COMMIT_THRESHOLD of the
            # attempted resync time, then sync back to c_rev.prev_timestamp
            # + 1...
            if ((c_rev.prev_timestamp + 1) - new_timestamp) \
                   < config.COMMIT_THRESHOLD:
              new_timestamp = c_rev.prev_timestamp + 1
              Log().warn("%s: Time set to %s"
                         % (warning_prefix, new_timestamp))
            else:
              Log().warn("%s: Timestamp left untouched" % warning_prefix)
              continue

          # If the new timestamp is later than that of our next revision
          elif c_rev.next_timestamp and new_timestamp > c_rev.next_timestamp:
            Log().warn(
                "%s: Attempt to set timestamp of revision %s on file %s"
                " to time %s, which is after time of next"
                " revision %s (%s):"
                % (warning_prefix, c_rev.rev, c_rev.cvs_path, new_timestamp,
                   c_rev.next_rev.rev, c_rev.next_timestamp))

            # If resyncing our rev to c_rev.next_timestamp - 1 will place
            # the timestamp of c_rev within COMMIT_THRESHOLD of the
            # attempted resync time, then sync forward to
            # c_rev.next_timestamp - 1...
            if (new_timestamp - (c_rev.next_timestamp - 1)) \
                   < config.COMMIT_THRESHOLD:
              new_timestamp = c_rev.next_timestamp - 1
              Log().warn("%s: Time set to %s"
                         % (warning_prefix, new_timestamp))
            else:
              Log().warn("%s: Timestamp left untouched" % warning_prefix)
              continue

          # Fix for Issue #71: Avoid resyncing two consecutive revisions
          # to the same timestamp.
          elif (new_timestamp == c_rev.prev_timestamp
                or new_timestamp == c_rev.next_timestamp):
            continue

          # adjust the time range. we want the COMMIT_THRESHOLD from the
          # bounds of the earlier/latest commit in this group.
          record[0] = min(record[0],
                          c_rev.timestamp - config.COMMIT_THRESHOLD/2)
          record[1] = max(record[1],
                          c_rev.timestamp + config.COMMIT_THRESHOLD/2)

          msg = "PASS2 RESYNC: '%s' (%s): old time='%s' delta=%ds" \
                % (c_rev.cvs_path, c_rev.rev, time.ctime(c_rev.timestamp),
                   new_timestamp - c_rev.timestamp)
          Log().verbose(msg)

          c_rev.timestamp = new_timestamp
          tweaked_timestamps_db[c_rev.unique_key()] = new_timestamp

          # stop looking for hits
          break

      output.write('%08lx %s %x\n'
                   % (c_rev.timestamp, c_rev.digest, c_rev.id,))
      cvs_revs_resync_db.log_revision(c_rev)
    Log().quiet("Done")


class SortRevsPass(Pass):
  """This pass was formerly known as pass3."""

  def register_artifacts(self):
    self._register_temp_file(config.SORTED_REVS_DATAFILE)
    self._register_temp_file_needed(config.CLEAN_REVS_DATAFILE)

  def run(self):
    Log().quiet("Sorting CVS revisions...")
    sort_file(artifact_manager.get_temp_file(config.CLEAN_REVS_DATAFILE),
              artifact_manager.get_temp_file(config.SORTED_REVS_DATAFILE))
    Log().quiet("Done")


class CreateDatabasesPass(Pass):
  """This pass was formerly known as pass4."""

  def register_artifacts(self):
    if not Ctx().trunk_only:
      self._register_temp_file(config.SYMBOL_LAST_CVS_REVS_DB)
    self._register_temp_file_needed(config.CVS_FILES_DB)
    self._register_temp_file_needed(config.CVS_REVS_RESYNC_DB)
    self._register_temp_file_needed(config.SORTED_REVS_DATAFILE)

  def run(self):
    """If we're not doing a trunk-only conversion, generate the
    LastSymbolicNameDatabase, which contains the last CVSRevision that
    is a source for each tag or branch.  Also record the remaining
    revisions to StatsKeeper()."""

    Log().quiet("Copying CVS revision data from flat file to database...")
    cvs_file_db = CVSFileDatabase(
        artifact_manager.get_temp_file(config.CVS_FILES_DB),
        database.DB_OPEN_READ)
    cvs_revs_db = CVSRevisionDatabase(
        cvs_file_db,
        artifact_manager.get_temp_file(config.CVS_REVS_RESYNC_DB),
        database.DB_OPEN_READ)
    if not Ctx().trunk_only:
      Log().quiet("Finding last CVS revisions for all symbolic names...")
      last_sym_name_db = LastSymbolicNameDatabase()
    else:
      # This is to avoid testing Ctx().trunk_only every time around the loop
      class DummyLSNDB:
        def noop(*args): pass
        log_revision = noop
        create_database = noop
      last_sym_name_db = DummyLSNDB()

    for line in fileinput.FileInput(
            artifact_manager.get_temp_file(config.SORTED_REVS_DATAFILE)):
      c_rev_id = line.strip().split()[-1]
      c_rev = cvs_revs_db.get_revision(c_rev_id)
      last_sym_name_db.log_revision(c_rev)
      StatsKeeper().record_c_rev(c_rev)

    StatsKeeper().set_stats_reflect_exclude(True)

    last_sym_name_db.create_database()
    StatsKeeper().archive()
    Log().quiet("Done")


class AggregateRevsPass(Pass):
  """Generate the SVNCommit <-> CVSRevision mapping databases.
  CVSCommit._commit also calls SymbolingsLogger to register
  CVSRevisions that represent an opening or closing for a path on a
  branch or tag.  See SymbolingsLogger for more details.

  This pass was formerly known as pass5."""

  def register_artifacts(self):
    self._register_temp_file(config.SYMBOL_OPENINGS_CLOSINGS)
    self._register_temp_file(config.SYMBOL_CLOSINGS_TMP)
    self._register_temp_file(config.SVN_REVNUMS_TO_CVS_REVS)
    self._register_temp_file(config.CVS_REVS_TO_SVN_REVNUMS)
    if not Ctx().trunk_only:
      self._register_temp_file_needed(config.SYMBOL_LAST_CVS_REVS_DB)
    self._register_temp_file_needed(config.CVS_FILES_DB)
    self._register_temp_file_needed(config.CVS_REVS_RESYNC_DB)
    self._register_temp_file_needed(config.TAGS_DB)
    self._register_temp_file_needed(config.DEFAULT_BRANCHES_DB)
    self._register_temp_file_needed(config.METADATA_DB)
    self._register_temp_file_needed(config.SORTED_REVS_DATAFILE)

  def run(self):
    Log().quiet("Mapping CVS revisions to Subversion commits...")

    cvs_file_db = CVSFileDatabase(
        artifact_manager.get_temp_file(config.CVS_FILES_DB),
        database.DB_OPEN_READ)
    cvs_revs_db = CVSRevisionDatabase(
        cvs_file_db,
        artifact_manager.get_temp_file(config.CVS_REVS_RESYNC_DB),
        database.DB_OPEN_READ)
    aggregator = CVSRevisionAggregator()
    for line in fileinput.FileInput(
            artifact_manager.get_temp_file(config.SORTED_REVS_DATAFILE)):
      c_rev_id = line.strip().split()[-1]
      c_rev = cvs_revs_db.get_revision(c_rev_id)
      if not (Ctx().trunk_only and c_rev.branch_name is not None):
        aggregator.process_revision(c_rev)
    aggregator.flush()

    StatsKeeper().set_svn_rev_count(SVNCommit.revnum - 1)
    StatsKeeper().archive()
    Log().quiet("Done")


class SortSymbolsPass(Pass):
  """This pass was formerly known as pass6."""

  def register_artifacts(self):
    if not Ctx().trunk_only:
      self._register_temp_file(config.SYMBOL_OPENINGS_CLOSINGS_SORTED)
    self._register_temp_file_needed(config.SYMBOL_OPENINGS_CLOSINGS)

  def run(self):
    Log().quiet("Sorting symbolic name source revisions...")

    if not Ctx().trunk_only:
      sort_file(
          artifact_manager.get_temp_file(config.SYMBOL_OPENINGS_CLOSINGS),
          artifact_manager.get_temp_file(
              config.SYMBOL_OPENINGS_CLOSINGS_SORTED))
    Log().quiet("Done")


class IndexSymbolsPass(Pass):
  """This pass was formerly known as pass7."""

  def register_artifacts(self):
    if not Ctx().trunk_only:
      self._register_temp_file(config.SYMBOL_OFFSETS_DB)
      self._register_temp_file_needed(config.SYMBOL_OPENINGS_CLOSINGS_SORTED)

  def run(self):
    Log().quiet("Determining offsets for all symbolic names...")

    def generate_offsets_for_symbolings():
      """This function iterates through all the lines in
      SYMBOL_OPENINGS_CLOSINGS_SORTED, writing out a file mapping
      SYMBOLIC_NAME to the file offset in SYMBOL_OPENINGS_CLOSINGS_SORTED
      where SYMBOLIC_NAME is first encountered.  This will allow us to
      seek to the various offsets in the file and sequentially read only
      the openings and closings that we need."""

      ###PERF This is a fine example of a db that can be in-memory and
      #just flushed to disk when we're done.  Later, it can just be sucked
      #back into memory.
      offsets_db = database.Database(
          artifact_manager.get_temp_file(config.SYMBOL_OFFSETS_DB),
          database.DB_OPEN_NEW)

      file = open(
          artifact_manager.get_temp_file(
              config.SYMBOL_OPENINGS_CLOSINGS_SORTED),
          'r')
      old_sym = ""
      while 1:
        fpos = file.tell()
        line = file.readline()
        if not line:
          break
        sym, svn_revnum, cvs_rev_key = line.split(" ", 2)
        if sym != old_sym:
          Log().verbose(" ", sym)
          old_sym = sym
          offsets_db[sym] = fpos

    if not Ctx().trunk_only:
      generate_offsets_for_symbolings()
    Log().quiet("Done.")


class OutputPass(Pass):
  """This pass was formerly known as pass8."""

  def register_artifacts(self):
    self._register_temp_file(config.SVN_MIRROR_REVISIONS_DB)
    self._register_temp_file(config.SVN_MIRROR_NODES_DB)
    self._register_temp_file_needed(config.CVS_FILES_DB)
    self._register_temp_file_needed(config.CVS_REVS_RESYNC_DB)
    self._register_temp_file_needed(config.TAGS_DB)
    self._register_temp_file_needed(config.METADATA_DB)
    self._register_temp_file_needed(config.SVN_REVNUMS_TO_CVS_REVS)
    self._register_temp_file_needed(config.CVS_REVS_TO_SVN_REVNUMS)
    if not Ctx().trunk_only:
      self._register_temp_file_needed(config.SYMBOL_OPENINGS_CLOSINGS_SORTED)
      self._register_temp_file_needed(config.SYMBOL_OFFSETS_DB)

  def run(self):
    svncounter = 2 # Repository initialization is 1.
    repos = SVNRepositoryMirror()
    persistence_manager = PersistenceManager(database.DB_OPEN_READ)

    if Ctx().target:
      if not Ctx().dry_run:
        repos.add_delegate(RepositoryDelegate())
      Log().quiet("Starting Subversion Repository.")
    else:
      if not Ctx().dry_run:
        repos.add_delegate(DumpfileDelegate())
      Log().quiet("Starting Subversion Dumpfile.")

    repos.add_delegate(StdoutDelegate(StatsKeeper().svn_rev_count()))

    while 1:
      svn_commit = persistence_manager.get_svn_commit(svncounter)
      if not svn_commit:
        break
      repos.commit(svn_commit)
      svncounter += 1

    repos.finish()


pass_manager = PassManager([
  CollectRevsPass(),
  ResyncRevsPass(),
  SortRevsPass(),
  CreateDatabasesPass(),
  AggregateRevsPass(),
  SortSymbolsPass(),
  IndexSymbolsPass(),
  OutputPass(),
  ])


def normalize_ttb_path(opt, path):
  """Normalize a path to be used for --trunk, --tags, or --branches.

  1. Strip leading, trailing, and duplicated '/'.
  2. Verify that the path is not empty.

  Return the normalized path.

  If the path is invalid, write an error message and exit."""

  norm_path = common.path_join(*path.split('/'))
  if not norm_path:
    raise FatalError("cannot pass an empty path to %s." % (opt,))
  return norm_path


def usage():
  print 'USAGE: %s [-v] [-s svn-repos-path] [-p pass] cvs-repos-path' \
        % os.path.basename(sys.argv[0])
  print '  --help, -h           print this usage message and exit with success'
  print '  --help-passes        list the available passes and their numbers'
  print '  --version            print the version number'
  print '  -q                   quiet'
  print '  -v                   verbose'
  print '  -s PATH              path for SVN repos'
  print '  -p PASS              execute only specified PASS'
  print '  -p [START]:[END]     execute passes START through END, inclusive'
  print '                       (PASS, START, and END can be pass names or numbers)'
  print '  --existing-svnrepos  load into existing SVN repository'
  print '  --dumpfile=PATH      name of intermediate svn dumpfile'
  print '  --tmpdir=PATH        directory to use for tmp data (default to cwd)'
  print '  --profile            profile with \'hotshot\' (into file cvs2svn.hotshot)'
  print '  --dry-run            do not create a repository or a dumpfile;'
  print '                       just print what would happen.'
  print '  --use-cvs            use CVS instead of RCS \'co\' to extract data'
  print '                       (only use this if having problems with RCS)'
  print '  --svnadmin=PATH      path to the svnadmin program'
  print '  --trunk-only         convert only trunk commits, not tags nor branches'
  print '  --trunk=PATH         path for trunk (default: %s)'    \
        % Ctx().trunk_base
  print '  --branches=PATH      path for branches (default: %s)' \
        % Ctx().branches_base
  print '  --tags=PATH          path for tags (default: %s)'     \
        % Ctx().tags_base
  print '  --no-prune           don\'t prune empty directories'
  print '  --dump-only          just produce a dumpfile, don\'t commit to a repos'
  print '  --encoding=ENC       encoding of paths and log messages in CVS repos'
  print '                       Multiple of these options may be passed, where they'
  print '                       will be treated as an ordered list of encodings to'
  print '                       attempt (with "ascii" as a hardcoded last resort)'
  print '  --force-branch=NAME  force NAME to be a branch'
  print '  --force-tag=NAME     force NAME to be a tag'
  print '  --exclude=REGEXP     exclude branches and tags matching REGEXP'
  print '  --symbol-transform=P:S transform symbol names from P to S where P and S'
  print '                       use Python regexp and reference syntax respectively'
  print '  --username=NAME      username for cvs2svn-synthesized commits'
  print '  --skip-cleanup       prevent the deletion of intermediate files'
  print '  --bdb-txn-nosync     pass --bdb-txn-nosync to "svnadmin create"'
  print '  --fs-type=TYPE       pass --fs-type=TYPE to "svnadmin create"'
  print '  --cvs-revnums        record CVS revision numbers as file properties'
  print '  --auto-props=FILE    set file properties from the auto-props section'
  print '                       of a file in svn config format'
  print '  --auto-props-ignore-case Ignore case when matching auto-props patterns'
  print '  --mime-types=FILE    specify an apache-style mime.types file for'
  print '                       setting svn:mime-type'
  print '  --eol-from-mime-type set svn:eol-style from mime type if known'
  print '  --no-default-eol     don\'t set svn:eol-style to \'native\' for'
  print '                       non-binary files with undetermined mime types'
  print '  --keywords-off       don\'t set svn:keywords on any files (by default,'
  print '                       cvs2svn sets svn:keywords on non-binary files to'
  print '                       "%s")' % config.SVN_KEYWORDS_VALUE


def main():
  # Convenience var, so we don't have to keep instantiating this Borg.
  ctx = Ctx()

  profiling = None
  start_pass = 1
  end_pass = pass_manager.num_passes

  try:
    opts, args = my_getopt(sys.argv[1:], 'p:s:qvh',
                               [ "help", "help-passes", "create", "trunk=",
                                 "username=", "existing-svnrepos",
                                 "branches=", "tags=", "encoding=",
                                 "force-branch=", "force-tag=", "exclude=",
                                 "use-cvs", "mime-types=",
                                 "auto-props=", "auto-props-ignore-case",
                                 "eol-from-mime-type", "no-default-eol",
                                 "trunk-only", "no-prune", "dry-run",
                                 "dump-only", "dumpfile=", "tmpdir=",
                                 "svnadmin=", "skip-cleanup", "cvs-revnums",
                                 "bdb-txn-nosync", "fs-type=",
                                 "version", "profile",
                                 "keywords-off", "symbol-transform="])
  except getopt.GetoptError, e:
    sys.stderr.write(error_prefix + ': ' + str(e) + '\n\n')
    usage()
    sys.exit(1)

  for opt, value in opts:
    if opt == '--version':
        print '%s version %s' % (os.path.basename(sys.argv[0]), VERSION)
        sys.exit(0)
    elif opt == '-p':
      if value.find(':') >= 0:
        start_pass, end_pass = value.split(':')
        start_pass = pass_manager.get_pass_number(start_pass, 1)
        end_pass = pass_manager.get_pass_number(end_pass,
                                                pass_manager.num_passes)
      else:
        end_pass = start_pass = pass_manager.get_pass_number(value)

      if not start_pass <= end_pass:
        raise InvalidPassError(
            'Ending pass must not come before starting pass.')
    elif (opt == '--help') or (opt == '-h'):
      ctx.print_help = 1
    elif opt == '--help-passes':
      pass_manager.help_passes()
      sys.exit(0)
    elif opt == '-v':
      Log().log_level = Log.VERBOSE
      ctx.verbose = 1
    elif opt == '-q':
      Log().log_level = Log.QUIET
      ctx.quiet = 1
    elif opt == '-s':
      ctx.target = value
    elif opt == '--existing-svnrepos':
      ctx.existing_svnrepos = 1
    elif opt == '--dumpfile':
      ctx.dumpfile = value
    elif opt == '--tmpdir':
      ctx.tmpdir = value
    elif opt == '--use-cvs':
      ctx.use_cvs = 1
    elif opt == '--svnadmin':
      ctx.svnadmin = value
    elif opt == '--trunk-only':
      ctx.trunk_only = 1
    elif opt == '--trunk':
      ctx.trunk_base = normalize_ttb_path(opt, value)
    elif opt == '--branches':
      ctx.branches_base = normalize_ttb_path(opt, value)
    elif opt == '--tags':
      ctx.tags_base = normalize_ttb_path(opt, value)
    elif opt == '--no-prune':
      ctx.prune = None
    elif opt == '--dump-only':
      ctx.dump_only = 1
    elif opt == '--dry-run':
      ctx.dry_run = 1
    elif opt == '--encoding':
      ctx.encoding.insert(-1, value)
    elif opt == '--force-branch':
      ctx.forced_branches.append(value)
    elif opt == '--force-tag':
      ctx.forced_tags.append(value)
    elif opt == '--exclude':
      try:
        ctx.excludes.append(re.compile('^' + value + '$'))
      except re.error, e:
        raise FatalError("'%s' is not a valid regexp." % (value,))
    elif opt == '--mime-types':
      ctx.mime_types_file = value
    elif opt == '--auto-props':
      ctx.auto_props_file = value
    elif opt == '--auto-props-ignore-case':
      ctx.auto_props_ignore_case = True
    elif opt == '--eol-from-mime-type':
      ctx.eol_from_mime_type = 1
    elif opt == '--no-default-eol':
      ctx.no_default_eol = 1
    elif opt == '--keywords-off':
      ctx.keywords_off = 1
    elif opt == '--username':
      ctx.username = value
    elif opt == '--skip-cleanup':
      ctx.skip_cleanup = 1
    elif opt == '--cvs-revnums':
      ctx.svn_property_setters.append(
          property_setters.CVSRevisionNumberSetter())
    elif opt == '--bdb-txn-nosync':
      ctx.bdb_txn_nosync = 1
    elif opt == '--fs-type':
      ctx.fs_type = value
    elif opt == '--create':
      sys.stderr.write(warning_prefix +
          ': The behaviour produced by the --create option is now the '
          'default,\nand passing the option is deprecated.\n')
    elif opt == '--profile':
      profiling = 1
    elif opt == '--symbol-transform':
      [pattern, replacement] = value.split(":")
      try:
        pattern = re.compile(pattern)
      except re.error, e:
        raise FatalError("'%s' is not a valid regexp." % (pattern,))
      ctx.symbol_transforms.append((pattern, replacement,))

  if ctx.print_help:
    usage()
    sys.exit(0)

  # Consistency check for options and arguments.
  if len(args) == 0:
    usage()
    sys.exit(1)

  if len(args) > 1:
    sys.stderr.write(error_prefix +
                     ": must pass only one CVS repository.\n")
    usage()
    sys.exit(1)

  cvsroot = args[0]

  if ctx.use_cvs:
    ctx.cvs_repository = cvs_repository.CVSRepositoryViaCVS(cvsroot)
  else:
    ctx.cvs_repository = cvs_repository.CVSRepositoryViaRCS(cvsroot)

  if (not ctx.target) and (not ctx.dump_only) and (not ctx.dry_run):
    raise FatalError("must pass one of '-s' or '--dump-only'.")

  def not_both(opt1val, opt1name, opt2val, opt2name):
    if opt1val and opt2val:
      raise FatalError("cannot pass both '%s' and '%s'."
                       % (opt1name, opt2name,))

  not_both(ctx.target, '-s',
           ctx.dump_only, '--dump-only')

  not_both(ctx.dump_only, '--dump-only',
           ctx.existing_svnrepos, '--existing-svnrepos')

  not_both(ctx.bdb_txn_nosync, '--bdb-txn-nosync',
           ctx.existing_svnrepos, '--existing-svnrepos')

  not_both(ctx.dump_only, '--dump-only',
           ctx.bdb_txn_nosync, '--bdb-txn-nosync')

  not_both(ctx.quiet, '-q',
           ctx.verbose, '-v')

  not_both(ctx.fs_type, '--fs-type',
           ctx.existing_svnrepos, '--existing-svnrepos')

  if ctx.fs_type and ctx.fs_type != 'bdb' and ctx.bdb_txn_nosync:
    raise FatalError("cannot pass --bdb-txn-nosync with --fs-type=%s."
                     % ctx.fs_type)

  # Create the default project (using ctx.trunk, ctx.branches, and ctx.tags):
  ctx.project = Project(ctx.cvs_repository.cvs_repos_path,
                        ctx.trunk_base, ctx.branches_base, ctx.tags_base)

  if ctx.existing_svnrepos and not os.path.isdir(ctx.target):
    raise FatalError("the svn-repos-path '%s' is not an "
                     "existing directory." % ctx.target)

  if not ctx.dump_only and not ctx.existing_svnrepos \
     and (not ctx.dry_run) and os.path.exists(ctx.target):
    raise FatalError("the svn-repos-path '%s' exists.\n"
                     "Remove it, or pass '--existing-svnrepos'."
                     % ctx.target)

  if ctx.target and not ctx.dry_run:
    # Verify that svnadmin can be executed.  The 'help' subcommand
    # should be harmless.
    try:
      check_command_runs([ctx.svnadmin, 'help'], 'svnadmin')
    except CommandFailedException, e:
      raise FatalError(
          '%s\n'
          'svnadmin could not be executed.  Please ensure that it is\n'
          'installed and/or use the --svnadmin option.' % (e,))

  ctx.svn_property_setters.append(
      property_setters.ExecutablePropertySetter())

  ctx.svn_property_setters.append(
      property_setters.BinaryFileEOLStyleSetter())

  if ctx.mime_types_file:
    ctx.svn_property_setters.append(
        property_setters.MimeMapper(ctx.mime_types_file))

  if ctx.auto_props_file:
    ctx.svn_property_setters.append(
        property_setters.AutoPropsPropertySetter(
            ctx.auto_props_file, ctx.auto_props_ignore_case))

  ctx.svn_property_setters.append(
      property_setters.BinaryFileDefaultMimeTypeSetter())

  if ctx.eol_from_mime_type:
    ctx.svn_property_setters.append(
        property_setters.EOLStyleFromMimeTypeSetter())

  if ctx.no_default_eol:
    ctx.svn_property_setters.append(
        property_setters.DefaultEOLStyleSetter(None))
  else:
    ctx.svn_property_setters.append(
        property_setters.DefaultEOLStyleSetter('native'))

  if not ctx.keywords_off:
    ctx.svn_property_setters.append(
        property_setters.KeywordsPropertySetter(config.SVN_KEYWORDS_VALUE))

  # Make sure the tmp directory exists.  Note that we don't check if
  # it's empty -- we want to be able to use, for example, "." to hold
  # tempfiles.  But if we *did* want check if it were empty, we'd do
  # something like os.stat(ctx.tmpdir)[stat.ST_NLINK], of course :-).
  if not os.path.exists(ctx.tmpdir):
    os.mkdir(ctx.tmpdir)
  elif not os.path.isdir(ctx.tmpdir):
    raise FatalError(
        "cvs2svn tried to use '%s' for temporary files, but that path\n"
        "  exists and is not a directory.  Please make it be a directory,\n"
        "  or specify some other directory for temporary files."
        % (ctx.tmpdir,))

  # But do lock the tmpdir, to avoid process clash.
  try:
    os.mkdir(os.path.join(ctx.tmpdir, 'cvs2svn.lock'))
  except OSError, e:
    if e.errno == errno.EACCES:
      raise FatalError("Permission denied:"
                       + " No write access to directory '%s'." % ctx.tmpdir)
    if e.errno == errno.EEXIST:
      raise FatalError(
          "cvs2svn is using directory '%s' for temporary files, but\n"
          "  subdirectory '%s/cvs2svn.lock' exists, indicating that another\n"
          "  cvs2svn process is currently using '%s' as its temporary\n"
          "  workspace.  If you are certain that is not the case,\n"
          "  then remove the '%s/cvs2svn.lock' subdirectory."
          % (ctx.tmpdir, ctx.tmpdir, ctx.tmpdir, ctx.tmpdir,))
    raise

  # Provide CVSRevision with a context that it can use:
  CVSRevision.ctx = ctx

  try:
    if profiling:
      import hotshot
      prof = hotshot.Profile('cvs2svn.hotshot')
      prof.runcall(pass_manager.run, start_pass, end_pass)
      prof.close()
    else:
      pass_manager.run(start_pass, end_pass)
  finally:
    try: os.rmdir(os.path.join(ctx.tmpdir, 'cvs2svn.lock'))
    except: pass


if __name__ == '__main__':
  try:
    main()
  except FatalException, e:
    sys.stderr.write(str(e))
    sys.exit(1)


